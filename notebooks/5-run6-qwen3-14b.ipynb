{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12443031,"sourceType":"datasetVersion","datasetId":7849167}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-02T15:19:32.380092Z","iopub.execute_input":"2025-08-02T15:19:32.380788Z","iopub.status.idle":"2025-08-02T15:19:32.685214Z","shell.execute_reply.started":"2025-08-02T15:19:32.380762Z","shell.execute_reply":"2025-08-02T15:19:32.684650Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/trec-2025/2025-starter-kit-main/.example.env\n/kaggle/input/trec-2025/2025-starter-kit-main/main.py\n/kaggle/input/trec-2025/2025-starter-kit-main/README.md\n/kaggle/input/trec-2025/2025-starter-kit-main/produce_run.py\n/kaggle/input/trec-2025/2025-starter-kit-main/output/tracking_data.json\n/kaggle/input/trec-2025/2025-starter-kit-main/output/dragun-organizers-starter-kit-task-1\n/kaggle/input/trec-2025/2025-starter-kit-main/output/dragun-organizers-starter-kit-task-2\n/kaggle/input/trec-2025/2025-starter-kit-main/data/trec-2025-dragun-topics.jsonl\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/report_generator.py\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/segment_retriever.py\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/question_generator.py\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/query_generator.py\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/information_evaluator.py\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%capture\nimport os\nif \"COLAB_\" not in \"\".join(os.environ.keys()):\n    !pip install unsloth\nelse:\n    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n    !pip install transformers==4.51.3\n    !pip install --no-deps unsloth\n    !pip install langchain langchain-community\n    !pip install jsonlines\n    !pip install --quiet langchain transformers sentencepiece\n\nimport pandas as pd\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.chains import LLMChain\nfrom transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\nimport json\nfrom unsloth import FastLanguageModel\nfrom unsloth import FastModel\nimport torch\nfrom tqdm import tqdm\nfrom unsloth.chat_templates import get_chat_template","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T15:19:32.686448Z","iopub.execute_input":"2025-08-02T15:19:32.686781Z","iopub.status.idle":"2025-08-02T15:20:45.984536Z","shell.execute_reply.started":"2025-08-02T15:19:32.686763Z","shell.execute_reply":"2025-08-02T15:20:45.983906Z"}},"outputs":[{"name":"stderr","text":"2025-08-02 15:20:20.342584: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754148020.522907      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754148020.573710      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"TOPICS_PATH = '/kaggle/input/trec-2025/2025-starter-kit-main/data/trec-2025-dragun-topics.jsonl'\n\ndef load_jsonl(fname):\n    with open(fname, 'r', encoding='utf-8') as f:\n        return [json.loads(line) for line in f]\ntopics = load_jsonl(TOPICS_PATH)\nprint(\"Loaded\", len(topics), \"topics.\")\n\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Qwen3-14B-unsloth-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)  \n\nfrom langchain.prompts import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T15:20:45.985328Z","iopub.execute_input":"2025-08-02T15:20:45.985603Z","iopub.status.idle":"2025-08-02T15:21:33.546674Z","shell.execute_reply.started":"2025-08-02T15:20:45.985556Z","shell.execute_reply":"2025-08-02T15:21:33.545645Z"}},"outputs":[{"name":"stdout","text":"Loaded 30 topics.\n==((====))==  Unsloth 2025.8.1: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 6.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00d50510d0d94d61aa0e123952de361e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da40d11d324d48fbbd726fcbd57ff5d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afd5fdb733324aef87c3cfdc2d4fa914"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.59G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78d8732e85ca40e585f5d1d92a031deb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/1.56G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"976f0bfd7a8b45ee9c5a36203e1ed4e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcc83cb2241148f182801c80a91e3dd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bf9376c9615438e8008b1255f4e1103"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1354cbf0949b4186a0d640ee257b553f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c8bd71c4b545f689f05150e7a1fd53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4652625f76c04e2080d4301402ef9691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbe0152baaee4b3d8b841814b5ffdf2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6a28b5017474b2d841606ee0dd74d0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5e2c930d2144eb5b8ac1a305506380c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9149c5df933d4e36a9384824cc2b9185"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import re\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.llms import HuggingFacePipeline\nfrom transformers import pipeline\n\n# 1. Enhanced Prompt with external resource-informed examples\nprompt_template = PromptTemplate(\n    input_variables=[\"title\", \"body\"],\n    template=(\n        \"You are an investigative fact-checking assistant trained on resources like PolitiFact, MBFC, and NewsQA.\\n\"\n        \"Your goal: Generate 10 sharp and critical questions a reader should ask to assess the credibility of a news article.\\n\\n\"\n\n        \"Focus on:\\n\"\n        \"- Source bias or affiliations\\n\"\n        \"- Factual accuracy and evidence\\n\"\n        \"- Omissions or one-sided reporting\\n\"\n        \"- Language framing (sensationalism)\\n\"\n        \"- Viewpoint diversity (centrists, right-wing, etc.)\\n\"\n        \"- Potential conflicts of interest\\n\\n\"\n\n        \"Guidelines:\\n\"\n        \"- Each question should be at most 300 characters.\\n\"\n        \"- Avoid compound questions (ask one thing at a time).\\n\"\n        \"- Avoid vague/general/overly broad questions.\\n\"\n        \"- Prioritize the most important and trust-assessing questions at the top.\\n\\n\"\n\n        \"Example 1 (Inspired by PolitiFact):\\n\"\n        \"Title: 'WHO: Processed meat causes cancer'\\n\"\n        \"Article: WHO classified processed meat as carcinogenic...\\n\"\n        \"Questions:\\n\"\n        \"1. What peer-reviewed studies support WHO's claim?\\n\"\n        \"2. Is the research methodology disclosed in the article?\\n\"\n        \"3. Who funded the studies mentioned?\\n\"\n        \"4. Are dissenting expert views included?\\n\"\n        \"5. Are the health risks exaggerated?\\n\"\n        \"6. Is primary data linked or cited?\\n\"\n        \"7. Does the article mention affected demographics?\\n\"\n        \"8. Are any advocacy groups quoted?\\n\"\n        \"9. Is causal language justified?\\n\"\n        \"10. Are the claims corroborated by other agencies?\\n\\n\"\n\n        \"Example 2 (MBFC-style analysis):\\n\"\n        \"Title: 'CDC says masks are optional outdoors'\\n\"\n        \"Article: CDC updates its outdoor masking guidance...\\n\"\n        \"Questions:\\n\"\n        \"1. Is there scientific consensus supporting this change?\\n\"\n        \"2. Does the article quote data or just opinion?\\n\"\n        \"3. Are counterarguments or dissenting experts cited?\\n\"\n        \"4. Are political motives or timing relevant?\\n\"\n        \"5. Is this consistent with international guidance?\\n\"\n        \"6. Does the article omit relevant prior CDC guidance?\\n\"\n        \"7. Are potential risks understated?\\n\"\n        \"8. Does the article rely on official or third-party data?\\n\"\n        \"9. Are specific regional risks acknowledged?\\n\"\n        \"10. Is the framing objective or emotionally loaded?\\n\\n\"\n\n        \"Now write 10 similar questions for this article:\\n\\n\"\n        \"Title: {title}\\n\"\n        \"Article text:\\n{body}\\n\\n\"\n        \"Output only the questions as a numbered list.\"\n    )\n)\n\n# 2. LLM Pipeline\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=600,\n    temperature=0.7,\n    do_sample=True,\n    return_full_text=False\n)\nllm = HuggingFacePipeline(pipeline=pipe)\nllm_chain = LLMChain(prompt=prompt_template, llm=llm, output_key=\"text\")\n\n# 3. Regex pattern for clean extraction\npattern = re.compile(r\"^\\s*\\d+[.)]\\s*(.+)$\")\n\n# 4. Extract unique questions (‚â§300 chars)\ndef extract_unique_questions(raw_text):\n    seen = set()\n    questions = []\n    for line in raw_text.strip().split(\"\\n\"):\n        match = pattern.match(line.strip())\n        if match:\n            question = match.group(1).strip()\n            if 0 < len(question) <= 300 and question not in seen:\n                seen.add(question)\n                questions.append(question)\n    return questions\n\n# 5. Main Processing Loop\nresults = []\nfor idx, topic in enumerate(topics):\n    docid = topic['docid']\n    title = topic.get('title', '').strip()\n    body = topic.get('body', '').strip()[:2000]\n\n    if not title and not body:\n        print(f\"‚ö†Ô∏è Skipping empty topic {docid}\")\n        continue\n\n    questions = []\n    for attempt in range(3):\n        output = llm_chain.invoke({\"title\": title, \"body\": body})\n        text = output['text'] if isinstance(output, dict) else output\n        questions = extract_unique_questions(text)\n\n        if len(questions) >= 10:\n            questions = questions[:10]\n            break\n        else:\n            print(f\"üîÅ Retry {attempt+1} for {docid} ‚Äî Got {len(questions)}\")\n\n    while len(questions) < 10:\n        questions.append(\"N/A\")\n\n    results.append({\n        \"docid\": docid,\n        \"questions\": questions\n    })\n\n# 6. Show Sample Output\nfor item in results[:3]:\n    print(f\"\\nDocID: {item['docid']}\")\n    for i, q in enumerate(item['questions'], 1):\n        print(f\"{i}. {q}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T15:21:33.548403Z","iopub.execute_input":"2025-08-02T15:21:33.548731Z","iopub.status.idle":"2025-08-02T15:47:43.917796Z","shell.execute_reply.started":"2025-08-02T15:21:33.548699Z","shell.execute_reply":"2025-08-02T15:47:43.917045Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3307494422.py:75: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm = HuggingFacePipeline(pipeline=pipe)\n/tmp/ipykernel_36/3307494422.py:76: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  llm_chain = LLMChain(prompt=prompt_template, llm=llm, output_key=\"text\")\n","output_type":"stream"},{"name":"stdout","text":"üîÅ Retry 1 for msmarco_v2.1_doc_08_300872161 ‚Äî Got 5\nüîÅ Retry 1 for msmarco_v2.1_doc_35_441326441 ‚Äî Got 6\nüîÅ Retry 1 for msmarco_v2.1_doc_38_227081897 ‚Äî Got 4\nüîÅ Retry 1 for msmarco_v2.1_doc_48_515287844 ‚Äî Got 6\n\nDocID: msmarco_v2.1_doc_04_420132660\n1. What evidence supports Sam Panopoulos as the inventor of Hawaiian pizza?\n2. Are there alternative claims about the origin of Hawaiian pizza not mentioned?\n3. Does the article cite primary sources or rely on secondary accounts?\n4. How does the article define \"Hawaiian pizza\" and its connection to Hawaii?\n5. What sources confirm the 1962 date and location of invention?\n6. Is there scholarly or historical research corroborating this origin story?\n7. Does the article address cultural or regional variations in pizza naming?\n8. Are there conflicting accounts from other restaurants or individuals?\n9. How does the article handle the term \"controversial\" in describing Hawaiian pizza?\n10. What role does the author‚Äôs affiliation with Gastro Obscura play in the narrative?\n\nDocID: msmarco_v2.1_doc_06_1440134319\n1. What peer-reviewed studies link instant noodles to cancer, stroke, and diabetes?\n2. Is the chemical TBHQ in instant noodles proven to cause cancer in humans or only in animal studies?\n3. Are the health risks of TBHQ and instant noodles exaggerated or based on inconclusive research?\n4. Does the article mention any counterarguments or dissenting scientific opinions?\n5. Who funded the studies cited in the article, and could there be conflicts of interest?\n6. Are the claims about instant noodles‚Äô dangers supported by major health organizations like the WHO or FDA?\n7. Does the article distinguish between instant noodles and traditional Japanese ramen?\n8. Are the risks of TBHQ and processed foods presented in a sensationalized or misleading way?\n9. Is the article‚Äôs author affiliated with any advocacy groups promoting anti-processed-food agendas?\n10. Are the health risks of instant noodles contextualized with their overall dietary impact or consumption frequency?\n\nDocID: msmarco_v2.1_doc_08_300872161\n1. What specific legal exemptions allow Coca-Cola to import coca leaves while the practice is illegal for others?\n2. What peer-reviewed studies confirm the safety of coca leaves in their natural form as claimed?\n3. Are there any documented instances of coca leaves being used to manufacture cocaine in the U.S.?\n4. What is the role of the Stepan Company in processing coca leaves for Coca-Cola, and is this process non-addictive?\n5. What evidence exists that Coca-Cola's coca leaf imports are linked to cocaine production in the U.S.?\n6. What scientific consensus exists regarding the claim that coca leaves are non-addictive and safe in their natural form?\n7. What legal or regulatory steps has the U.S. government taken to prevent coca leaf imports for cocaine production?\n8. What is the historical accuracy of the claim that Coca-Cola originally contained cocaine?\n9. What is the source of the assertion that the U.S. government actively eradicates coca crops in Andean countries?\n10. Are there alternative explanations for why Coca-Cola is the only company allowed to import coca leaves legally?1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\nteam_id = \"CUET\"\nrun_id = \"CUET-qwen14B-v1\"\n\nsubmission_rows = []\n\nfor item in results:\n    topic_id = item[\"docid\"]\n    for rank, question in enumerate(item[\"questions\"], 1):\n        # Clean question of unwanted tabs/newlines\n        clean_q = question.replace('\\t', ' ').replace('\\n', ' ').strip()\n        submission_rows.append([\n            topic_id,\n            team_id,\n            run_id,\n            rank,\n            clean_q\n        ])\n\n# Create DataFrame and save\ndf = pd.DataFrame(submission_rows, columns=[\"topic_id\", \"team_id\", \"run_id\", \"rank\", \"question\"])\ndf.to_csv(\"/kaggle/working/CUET_run6.tsv\", sep=\"\\t\", index=False, header=False, encoding=\"utf-8\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T15:47:43.918566Z","iopub.execute_input":"2025-08-02T15:47:43.918845Z","iopub.status.idle":"2025-08-02T15:47:43.942421Z","shell.execute_reply.started":"2025-08-02T15:47:43.918825Z","shell.execute_reply":"2025-08-02T15:47:43.941746Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Show duplicated questions (exact text matches)\nduplicates = df[df.duplicated('question', keep=False)]\nnum_duplicates = len(duplicates)\n\nprint(f\"üîç Found {num_duplicates} duplicated question rows.\\n\")\nif num_duplicates > 0:\n    print(\"üìÑ Duplicated questions (full rows):\")\n    display(duplicates)\n\n# Frequency count of duplicate questions\nprint(\"\\nüìä Questions that appear more than once:\")\nduplicate_counts = df['question'].value_counts()\ndisplay(duplicate_counts[duplicate_counts > 1])\n\n# Check for 'N/A' values (both literal string and NaN)\nna_mask = df['question'].isna() | (df['question'].str.strip().str.upper() == 'N/A')\nna_rows = df[na_mask]\n\nprint(f\"\\n‚ö†Ô∏è Found {len(na_rows)} rows with 'N/A' or missing question values.\\n\")\nif len(na_rows) > 0:\n    print(\"üö´ Rows with N/A or missing questions:\")\n    display(na_rows)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T15:51:06.210141Z","iopub.execute_input":"2025-08-02T15:51:06.210804Z","iopub.status.idle":"2025-08-02T15:51:06.222396Z","shell.execute_reply.started":"2025-08-02T15:51:06.210778Z","shell.execute_reply":"2025-08-02T15:51:06.221844Z"}},"outputs":[{"name":"stdout","text":"üîç Found 0 duplicated question rows.\n\n\nüìä Questions that appear more than once:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Series([], Name: count, dtype: int64)"},"metadata":{}},{"name":"stdout","text":"\n‚ö†Ô∏è Found 0 rows with 'N/A' or missing question values.\n\n","output_type":"stream"}],"execution_count":7}]}