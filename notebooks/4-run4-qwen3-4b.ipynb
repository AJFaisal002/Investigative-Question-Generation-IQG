{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12443031,"sourceType":"datasetVersion","datasetId":7849167}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-02T08:54:44.199166Z","iopub.execute_input":"2025-08-02T08:54:44.199983Z","iopub.status.idle":"2025-08-02T08:54:44.210825Z","shell.execute_reply.started":"2025-08-02T08:54:44.199958Z","shell.execute_reply":"2025-08-02T08:54:44.209933Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/trec-2025/2025-starter-kit-main/.example.env\n/kaggle/input/trec-2025/2025-starter-kit-main/main.py\n/kaggle/input/trec-2025/2025-starter-kit-main/README.md\n/kaggle/input/trec-2025/2025-starter-kit-main/produce_run.py\n/kaggle/input/trec-2025/2025-starter-kit-main/output/tracking_data.json\n/kaggle/input/trec-2025/2025-starter-kit-main/output/dragun-organizers-starter-kit-task-1\n/kaggle/input/trec-2025/2025-starter-kit-main/output/dragun-organizers-starter-kit-task-2\n/kaggle/input/trec-2025/2025-starter-kit-main/data/trec-2025-dragun-topics.jsonl\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/report_generator.py\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/segment_retriever.py\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/question_generator.py\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/query_generator.py\n/kaggle/input/trec-2025/2025-starter-kit-main/modules/information_evaluator.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"%%capture\nimport os\nif \"COLAB_\" not in \"\".join(os.environ.keys()):\n    !pip install unsloth\nelse:\n    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n    !pip install transformers==4.51.3\n    !pip install --no-deps unsloth\n    !pip install langchain langchain-community\n    !pip install jsonlines\n    !pip install --quiet langchain transformers sentencepiece\n\nimport pandas as pd\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.chains import LLMChain\nfrom transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\nimport json\nfrom unsloth import FastLanguageModel\nfrom unsloth import FastModel\nimport torch\nfrom tqdm import tqdm\nfrom unsloth.chat_templates import get_chat_template","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T08:54:44.212405Z","iopub.execute_input":"2025-08-02T08:54:44.212664Z","iopub.status.idle":"2025-08-02T08:55:05.700326Z","shell.execute_reply.started":"2025-08-02T08:54:44.212645Z","shell.execute_reply":"2025-08-02T08:55:05.699407Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"TOPICS_PATH = '/kaggle/input/trec-2025/2025-starter-kit-main/data/trec-2025-dragun-topics.jsonl'\n\ndef load_jsonl(fname):\n    with open(fname, 'r', encoding='utf-8') as f:\n        return [json.loads(line) for line in f]\ntopics = load_jsonl(TOPICS_PATH)\nprint(\"Loaded\", len(topics), \"topics.\")\n\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Qwen3-4B\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)  \n\nfrom langchain.prompts import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T08:55:05.701742Z","iopub.execute_input":"2025-08-02T08:55:05.702487Z","iopub.status.idle":"2025-08-02T08:55:13.413097Z","shell.execute_reply.started":"2025-08-02T08:55:05.702437Z","shell.execute_reply":"2025-08-02T08:55:13.412349Z"}},"outputs":[{"name":"stdout","text":"Loaded 30 topics.\n==((====))==  Unsloth 2025.7.11: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 6.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# import re\n# from langchain.prompts import PromptTemplate\n# from langchain.chains import LLMChain\n# from langchain.llms import HuggingFacePipeline\n# from transformers import pipeline\n\n# # 1. Enhanced Prompt Template with few-shot examples and new ordering instruction\n# prompt_template = PromptTemplate(\n#     input_variables=[\"title\", \"body\"],\n#     template=(\n#         \"You are an expert research assistant. Read the news article below carefully.\\n\"\n#         \"Your task: Generate 10 critical investigative questions that a thoughtful reader should ask \"\n#         \"to assess the article's trustworthiness, focusing on source bias, motivation, viewpoint diversity \"\n#         \"(including centrist and right-wing perspectives), and factual accuracy.\\n\"\n#         \"Avoid vague or compound questions. Each question must be under 300 characters.\\n\\n\"\n\n#         \"Rank the questions so that the most important and trust-assessing appear at the top.\\n\\n\"\n\n#         \"Example 1:\\n\"\n#         \"Title: 'WHO: Processed meat causes cancer'\\n\"\n#         \"Article text: WHO has classified processed meat as carcinogenic...\\n\"\n#         \"Questions:\\n\"\n#         \"1. What research supports the WHO's classification of processed meat?\\n\"\n#         \"2. Who funded the cited studies on cancer and meat consumption?\\n\"\n#         \"3. Are alternative expert opinions presented in the article?\\n\"\n#         \"4. Is statistical data in the article properly attributed?\\n\"\n#         \"5. Does the article provide any counterarguments?\\n\"\n#         \"6. Are potential conflicts of interest disclosed?\\n\"\n#         \"7. Is there mention of population differences in risk?\\n\"\n#         \"8. Is sensational language used to exaggerate findings?\\n\"\n#         \"9. Does the article include primary sources or links?\\n\"\n#         \"10. Are the health claims consistent with other organizations?\\n\\n\"\n\n#         \"Example 2:\\n\"\n#         \"Title: 'CDC says masks are optional outdoors'\\n\"\n#         \"Article text: New CDC guidelines suggest masks are no longer necessary...\\n\"\n#         \"Questions:\\n\"\n#         \"1. What scientific evidence is used to support this guideline?\\n\"\n#         \"2. Does the article quote public health officials directly?\\n\"\n#         \"3. Are there experts who disagree with the CDC's stance?\\n\"\n#         \"4. Are specific situations where masks are still needed mentioned?\\n\"\n#         \"5. Does the article specify data sources for transmission risk?\\n\"\n#         \"6. Are regional COVID-19 differences addressed?\\n\"\n#         \"7. Are the potential political implications discussed?\\n\"\n#         \"8. Is past CDC guidance compared to current updates?\\n\"\n#         \"9. Are international guidelines referenced?\\n\"\n#         \"10. Are any counterfactual scenarios analyzed?\\n\\n\"\n\n#         \"Now generate 10 similar questions for the following article:\\n\\n\"\n#         \"Title: {title}\\n\\n\"\n#         \"Article text:\\n{body}\\n\\n\"\n#         \"Output only the questions as a numbered list:\\n\"\n#     )\n# )\n\n# # 2. Pipeline\n# pipe = pipeline(\n#     \"text-generation\",\n#     model=model,\n#     tokenizer=tokenizer,\n#     max_new_tokens=600,\n#     temperature=0.7,\n#     do_sample=True,\n#     return_full_text=False\n# )\n\n# llm = HuggingFacePipeline(pipeline=pipe)\n\n# llm_chain = LLMChain(\n#     prompt=prompt_template,\n#     llm=llm,\n#     output_key=\"text\"\n# )\n\n# # 3. Regex pattern for 1. Question format\n# pattern = re.compile(r\"^\\s*\\d+[.)]\\s*(.+)$\")\n\n# # 4. Output container\n# results = []\n\n# # 5. Function to extract clean questions\n# def extract_questions(raw_text):\n#     questions = []\n#     for line in raw_text.strip().split(\"\\n\"):\n#         match = pattern.match(line.strip())\n#         if match:\n#             question = match.group(1).strip()\n#             if 0 < len(question) <= 300:\n#                 questions.append(question)\n#     return questions\n\n# # 6. Heuristic scoring function for ranking trustworthiness questions\n# KEYWORDS = [\n#     'bias', 'motivation', 'viewpoint', 'right-wing', 'centrist',\n#     'diversity', 'balance', 'perspective', 'agenda', 'conflict of interest',\n#     'credibility', 'trustworthiness', 'fairness', 'opinion', 'sources'\n# ]\n\n# def score_question(q):\n#     q_lower = q.lower()\n#     return sum(1 for kw in KEYWORDS if kw in q_lower)\n\n# # 7. Main generation loop with intelligent retry and ranking\n# for idx, topic in enumerate(topics):\n#     docid = topic['docid']\n#     title = topic.get('title', '').strip()\n#     body = topic.get('body', '').strip()[:2000]\n\n#     if not title and not body:\n#         print(f\"‚ö†Ô∏è Skipping empty topic {docid}\")\n#         continue\n\n#     questions = []\n#     for attempt in range(3):  # Up to 3 tries\n#         output = llm_chain.invoke({\"title\": title, \"body\": body})\n#         text = output['text'] if isinstance(output, dict) else output\n#         questions = extract_questions(text)\n\n#         if len(questions) >= 10:\n#             # Sort by score, keep best 10\n#             questions = sorted(questions, key=score_question, reverse=True)[:10]\n#             break\n#         else:\n#             print(f\"üîÅ Retry {attempt + 1} for {docid} ‚Äî Got {len(questions)} questions\")\n\n#     # Fill with 'N/A' if still less than 10 after retries\n#     while len(questions) < 10:\n#         questions.append(\"N/A\")\n\n#     results.append({\n#         \"docid\": docid,\n#         \"questions\": questions\n#     })\n\n# # 8. Print first 3 docs\n# for item in results[:3]:\n#     print(f\"\\nDocID: {item['docid']}\")\n#     for i, q in enumerate(item['questions'], 1):\n#         print(f\"{i}. {q}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T08:55:13.414762Z","iopub.execute_input":"2025-08-02T08:55:13.415022Z","iopub.status.idle":"2025-08-02T08:55:13.421827Z","shell.execute_reply.started":"2025-08-02T08:55:13.415004Z","shell.execute_reply":"2025-08-02T08:55:13.420928Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import re\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.llms import HuggingFacePipeline\nfrom transformers import pipeline\n\n# 1. Enhanced Prompt Template with few-shot examples and new ordering instruction\nprompt_template = PromptTemplate(\n    input_variables=[\"title\", \"body\"],\n    template=(\n        \"You are an expert research assistant. Read the news article below carefully.\\n\"\n        \"Your task: Generate 10 critical investigative questions that a thoughtful reader should ask \"\n        \"to assess the article's trustworthiness, focusing on source bias, motivation, viewpoint diversity \"\n        \"(including centrist and right-wing perspectives), and factual accuracy.\\n\"\n        \"Avoid vague or compound questions. Each question must be under 300 characters.\\n\\n\"\n\n        \"Rank the questions so that the most important and trust-assessing appear at the top.\\n\\n\"\n\n        \"Example 1:\\n\"\n        \"Title: 'WHO: Processed meat causes cancer'\\n\"\n        \"Article text: WHO has classified processed meat as carcinogenic...\\n\"\n        \"Questions:\\n\"\n        \"1. What research supports the WHO's classification of processed meat?\\n\"\n        \"2. Who funded the cited studies on cancer and meat consumption?\\n\"\n        \"3. Are alternative expert opinions presented in the article?\\n\"\n        \"4. Is statistical data in the article properly attributed?\\n\"\n        \"5. Does the article provide any counterarguments?\\n\"\n        \"6. Are potential conflicts of interest disclosed?\\n\"\n        \"7. Is there mention of population differences in risk?\\n\"\n        \"8. Is sensational language used to exaggerate findings?\\n\"\n        \"9. Does the article include primary sources or links?\\n\"\n        \"10. Are the health claims consistent with other organizations?\\n\\n\"\n\n        \"Example 2:\\n\"\n        \"Title: 'CDC says masks are optional outdoors'\\n\"\n        \"Article text: New CDC guidelines suggest masks are no longer necessary...\\n\"\n        \"Questions:\\n\"\n        \"1. What scientific evidence is used to support this guideline?\\n\"\n        \"2. Does the article quote public health officials directly?\\n\"\n        \"3. Are there experts who disagree with the CDC's stance?\\n\"\n        \"4. Are specific situations where masks are still needed mentioned?\\n\"\n        \"5. Does the article specify data sources for transmission risk?\\n\"\n        \"6. Are regional COVID-19 differences addressed?\\n\"\n        \"7. Are the potential political implications discussed?\\n\"\n        \"8. Is past CDC guidance compared to current updates?\\n\"\n        \"9. Are international guidelines referenced?\\n\"\n        \"10. Are any counterfactual scenarios analyzed?\\n\\n\"\n\n        \"Now generate 10 similar questions for the following article:\\n\\n\"\n        \"Title: {title}\\n\\n\"\n        \"Article text:\\n{body}\\n\\n\"\n        \"Output only the questions as a numbered list:\\n\"\n    )\n)\n\n# 2. Pipeline\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=600,\n    temperature=0.7,\n    do_sample=True,\n    return_full_text=False\n)\nllm = HuggingFacePipeline(pipeline=pipe)\nllm_chain = LLMChain(prompt=prompt_template, llm=llm, output_key=\"text\")\n\n# 3. Regex for extracting 1. ..., 2. ... format\npattern = re.compile(r\"^\\s*\\d+[.)]\\s*(.+)$\")\n\n# 4. Extraction function with de-duplication\ndef extract_unique_questions(raw_text):\n    seen = set()\n    questions = []\n    for line in raw_text.strip().split(\"\\n\"):\n        match = pattern.match(line.strip())\n        if match:\n            question = match.group(1).strip()\n            if 0 < len(question) <= 300 and question not in seen:\n                seen.add(question)\n                questions.append(question)\n    return questions\n\n# 5. Main loop\nresults = []\nfor idx, topic in enumerate(topics):\n    docid = topic['docid']\n    title = topic.get('title', '').strip()\n    body = topic.get('body', '').strip()[:2000]\n\n    if not title and not body:\n        print(f\"‚ö†Ô∏è Skipping empty topic {docid}\")\n        continue\n\n    questions = []\n    for attempt in range(3):  # Retry 3 times if needed\n        output = llm_chain.invoke({\"title\": title, \"body\": body})\n        text = output['text'] if isinstance(output, dict) else output\n        questions = extract_unique_questions(text)\n\n        if len(questions) >= 10:\n            questions = questions[:10]  # Truncate to 10 if more\n            break\n        else:\n            print(f\"üîÅ Retry {attempt+1} for {docid} ‚Äî Got {len(questions)} unique questions\")\n\n    # Fill with 'N/A' if less than 10\n    while len(questions) < 10:\n        questions.append(\"N/A\")\n\n    results.append({\n        \"docid\": docid,\n        \"questions\": questions\n    })\n\n# 6. Show a few examples\nfor item in results[:3]:\n    print(f\"\\nDocID: {item['docid']}\")\n    for i, q in enumerate(item['questions'], 1):\n        print(f\"{i}. {q}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T08:55:13.422745Z","iopub.execute_input":"2025-08-02T08:55:13.422988Z","iopub.status.idle":"2025-08-02T09:12:51.366379Z","shell.execute_reply.started":"2025-08-02T08:55:13.422961Z","shell.execute_reply":"2025-08-02T09:12:51.365426Z"}},"outputs":[{"name":"stdout","text":"üîÅ Retry 1 for msmarco_v2.1_doc_34_7751734 ‚Äî Got 0 unique questions\nüîÅ Retry 1 for msmarco_v2.1_doc_52_1666095905 ‚Äî Got 0 unique questions\n\nDocID: msmarco_v2.1_doc_04_420132660\n1. What is the source of the claim that Sam Panopoulos invented the Hawaiian pizza?\n2. Does the article cite any historical records or primary sources to support the invention story?\n3. Are alternative explanations for the pizza's origin presented?\n4. Are there any known conflicts of interest among the authors or contributors?\n5. What is the perspective of Greek or Canadian historians on the pizza's origin?\n6. Does the article address the cultural significance of the pizza in both Canada and Hawaii?\n7. Are there any counterarguments or rebuttals from Hawaiian or Canadian cultural representatives?\n8. What is the historical context of pizza in Canada and its evolution over time?\n9. Does the article provide any evidence of the pizza's spread from Canada to Hawaii?\n10. Are there any alternative theories about the pizza's origin that are not mentioned?\n\nDocID: msmarco_v2.1_doc_06_1440134319\n1. What research supports the link between instant noodles and cancer?\n2. Who funded the studies cited in the article about TBHQ and cancer?\n3. Are alternative expert opinions presented in the article?\n4. Does the article provide evidence of TBHQ's safety in small doses?\n5. Are potential conflicts of interest among the cited researchers disclosed?\n6. Is there mention of population differences in health risks?\n7. Are specific health risks of TBHQ beyond cancer addressed?\n8. Are there experts who disagree with the findings on TBHQ?\n9. Is the article's source (Jenny Hills) qualified to comment on TBHQ?\n10. Does the article differentiate between instant noodles and real Japanese Ramen?\n\nDocID: msmarco_v2.1_doc_08_300872161\n1. What is the source of the article, and is it a reputable news outlet?\n2. What is the author's affiliation, and does it appear to be biased?\n3. Are there alternative viewpoints from mainstream media or scientific organizations?\n4. What is the legal status of coca leaf imports in the U.S., and how does it relate to Coca-Cola's exemption?\n5. Is the claim about Coca-Cola's original formula containing cocaine supported by credible sources?\n6. Does the article present any counterarguments to the U.S. eradication policy?\n7. Are there any conflicts of interest in the author's background or affiliations?\n8. What is the historical context of the Jones-Miller Act and its impact on cocaine imports?\n9. Are the health claims about coca leaves in their natural form accurate and properly cited?\n10. Does the article acknowledge the potential for misuse of coca leaves in processed forms?\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\n\nteam_id = \"CUET\"\nrun_id = \"CUET-qwen4B-v3\"\n\nsubmission_rows = []\n\nfor item in results:\n    topic_id = item[\"docid\"]\n    for rank, question in enumerate(item[\"questions\"], 1):\n        # Clean question of unwanted tabs/newlines\n        clean_q = question.replace('\\t', ' ').replace('\\n', ' ').strip()\n        submission_rows.append([\n            topic_id,\n            team_id,\n            run_id,\n            rank,\n            clean_q\n        ])\n\n# Create DataFrame and save\ndf = pd.DataFrame(submission_rows, columns=[\"topic_id\", \"team_id\", \"run_id\", \"rank\", \"question\"])\ndf.to_csv(\"/kaggle/working/CUET_run4.tsv\", sep=\"\\t\", index=False, header=False, encoding=\"utf-8\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T09:12:51.367553Z","iopub.execute_input":"2025-08-02T09:12:51.367888Z","iopub.status.idle":"2025-08-02T09:12:51.379952Z","shell.execute_reply.started":"2025-08-02T09:12:51.367868Z","shell.execute_reply":"2025-08-02T09:12:51.379070Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"df[50:70]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T09:12:51.380886Z","iopub.execute_input":"2025-08-02T09:12:51.381153Z","iopub.status.idle":"2025-08-02T09:12:51.401095Z","shell.execute_reply.started":"2025-08-02T09:12:51.381124Z","shell.execute_reply":"2025-08-02T09:12:51.400361Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                          topic_id team_id          run_id  rank  \\\n50  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3     1   \n51  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3     2   \n52  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3     3   \n53  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3     4   \n54  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3     5   \n55  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3     6   \n56  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3     7   \n57  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3     8   \n58  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3     9   \n59  msmarco_v2.1_doc_22_1648697797    CUET  CUET-qwen4B-v3    10   \n60   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3     1   \n61   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3     2   \n62   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3     3   \n63   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3     4   \n64   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3     5   \n65   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3     6   \n66   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3     7   \n67   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3     8   \n68   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3     9   \n69   msmarco_v2.1_doc_25_481628070    CUET  CUET-qwen4B-v3    10   \n\n                                             question  \n50  What is the source of the allegations against ...  \n51  Are the alleged texts or screenshots verified ...  \n52  Does the article present any counterarguments ...  \n53  Are the allegations consistent with any known ...  \n54  What is the credibility of the individuals cit...  \n55  Does the article mention any expert opinions o...  \n56  Are there alternative explanations for the all...  \n57  Are the allegations' implications on Armie Ham...  \n58  Does the article provide context on the broade...  \n59  Are there any potential conflicts of interest ...  \n60  What is the source of the claim that Momo is n...  \n61  Are the sources cited in the article independe...  \n62  Does the article present alternative viewpoint...  \n63  Is the article's stance on the Momo Challenge ...  \n64  What evidence is provided to refute the Momo C...  \n65  Are there any credible experts or organization...  \n66  Does the article acknowledge the potential for...  \n67  What is the historical context of the Momo Cha...  \n68  Are there any counterarguments or rebuttals fr...  \n69  Does the article discuss the role of social me...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>team_id</th>\n      <th>run_id</th>\n      <th>rank</th>\n      <th>question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>50</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>1</td>\n      <td>What is the source of the allegations against ...</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>2</td>\n      <td>Are the alleged texts or screenshots verified ...</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>3</td>\n      <td>Does the article present any counterarguments ...</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>4</td>\n      <td>Are the allegations consistent with any known ...</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>5</td>\n      <td>What is the credibility of the individuals cit...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>6</td>\n      <td>Does the article mention any expert opinions o...</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>7</td>\n      <td>Are there alternative explanations for the all...</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>8</td>\n      <td>Are the allegations' implications on Armie Ham...</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>9</td>\n      <td>Does the article provide context on the broade...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>msmarco_v2.1_doc_22_1648697797</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>10</td>\n      <td>Are there any potential conflicts of interest ...</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>1</td>\n      <td>What is the source of the claim that Momo is n...</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>2</td>\n      <td>Are the sources cited in the article independe...</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>3</td>\n      <td>Does the article present alternative viewpoint...</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>4</td>\n      <td>Is the article's stance on the Momo Challenge ...</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>5</td>\n      <td>What evidence is provided to refute the Momo C...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>6</td>\n      <td>Are there any credible experts or organization...</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>7</td>\n      <td>Does the article acknowledge the potential for...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>8</td>\n      <td>What is the historical context of the Momo Cha...</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>9</td>\n      <td>Are there any counterarguments or rebuttals fr...</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>msmarco_v2.1_doc_25_481628070</td>\n      <td>CUET</td>\n      <td>CUET-qwen4B-v3</td>\n      <td>10</td>\n      <td>Does the article discuss the role of social me...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# Show duplicated questions (exact text matches)\nduplicates = df[df.duplicated('question', keep=False)]\n\nprint(f\"Found {len(duplicates)} duplicated question rows\")\nduplicates\n\ndf['question'].value_counts()[df['question'].value_counts() > 1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T09:16:45.294844Z","iopub.execute_input":"2025-08-02T09:16:45.295648Z","iopub.status.idle":"2025-08-02T09:16:45.305235Z","shell.execute_reply.started":"2025-08-02T09:16:45.295624Z","shell.execute_reply":"2025-08-02T09:16:45.304428Z"}},"outputs":[{"name":"stdout","text":"Found 0 duplicated question rows\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Series([], Name: count, dtype: int64)"},"metadata":{}}],"execution_count":25}]}