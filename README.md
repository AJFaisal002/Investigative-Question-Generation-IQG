# Investigative Question Generation (IQG) using Qwen-based LLMs

A **LangChain-driven, multi-stage prompting framework** that systematically generates ranked investigative questions from news articles.  
This framework evaluates **trustworthiness, bias, and factual accuracy**, combining structured prompts, Qwen-based LLMs, LangChain execution, and controlled decoding.

---

## ğŸ“ Project Structure

| Folder | Description |
|--------|--------------|
| **notebooks/** | Jupyter notebooks for all 5 model runs (run10, run7, run8, run4, run6) |
| **figures/** | Methodology and visualization images for the research paper |
| **results/** | Evaluation scores, charts, and model comparison metrics |
| **docs/** | Supplementary notes, references, and documentation |

---

## âš™ï¸ Methodology Overview

The pipeline follows a **four-stage workflow**:

### **1ï¸âƒ£ Data Preparation**
- Input: TREC DRAGUN news articles (`docid`, `title`, `body`)  
- Cleaning, tokenization, truncation to 2000 characters  
- Output: Preprocessed text ready for model input  

### **2ï¸âƒ£ Prompt Construction & LLM Execution**
- Structured prompt template for investigative question generation (fact-checking, bias, evidence tracing)  
- Framework: **LangChain + HuggingFace + Qwen-based LLMs (Qwen3-14B / Qwen3-4B)**  
- Parameters:  
  - `temperature = 0.6â€“0.7`  
  - `top_p = 0.9`  
  - `max_new_tokens = 600`  
- Output: 10 investigative questions per article  

### **3ï¸âƒ£ Post-Processing**
- Remove duplicates  
- Filter short or empty questions  
- Pad list to ensure 10 questions per article  

### **4ï¸âƒ£ Evaluation & Reporting**
- Human/task-based scoring (coverage, coherence, novelty, bias detection)  
- Comparative evaluation across all model runs  

---

## ğŸ§© Model Runs and Performance

| Run ID | Model | Avg. Score | Notes |
|--------|--------|-------------|--------|
| `run10_qwen3_14B` | **Qwen3-14B-v5** | ğŸ¥‡ **0.76** | Best consistency and topic coverage |
| `run7_qwen3_14B` | **Qwen3-14B-v3** | ğŸ¥ˆ **0.70** | Stable results |
| `run8_qwen3_14B_top_p` | **Qwen3-14B-v3** | ğŸ¥‰ **0.63** | Balanced, moderate variation |
| `run4_qwen3_4B` | **Qwen3-4B-v3** | 0.55 | Good smaller model performance |
| `run6_qwen3_14B` | **Qwen3-14B-v1** | 0.48 | Early baseline version |

---

## ğŸ§  Tech Stack

- ğŸ **Python 3.10+**  
- ğŸ§© **LangChain** â€” for LLM orchestration  
- ğŸ¤— **HuggingFace Transformers** â€” for Qwen model integration  
- ğŸ§® **Qwen3-14B / Qwen3-4B Models**  
- ğŸ“Š **Pandas, Matplotlib** â€” for analysis and visualization  
- ğŸ““ **Jupyter Notebook** â€” for experimentation and research documentation  

---

## ğŸš€ How to Run

```bash
# Clone this repository
git clone https://github.com/AJFaisal002/Investigative-Question-Generation-IQG.git
cd Investigative-Question-Generation-IQG

# Install dependencies
pip install -r requirements.txt

# Run notebooks
jupyter notebook notebooks/

```


ğŸ‘¤ Author

## Adnan Faisal Email: **ajfaisal1208023@gmail.com**
## Shiti Chowdhury  Email: **shitichowdhury21@gmail.com**
### Department of Computer Science & Engineering**
### Chittagong University of Engineering & Technology (CUET)**

